{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ekstraksi dan Pengolahan Data Kepemilikan Tanah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Menyiapkan coding environment, termasuk menginstall dan/atau memperbarui library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pytesseract in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytesseract) (10.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pdf2image in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdf2image) (10.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pillow in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (10.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\emirp\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Menginstall library-library\n",
    "%pip install pandas\n",
    "%pip install pytesseract\n",
    "%pip install pdf2image\n",
    "%pip install pillow\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install tensorflow\n",
    "%pip install opencv-python\n",
    "\n",
    "# Mengimport library-library untuk digunakan\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the preprocessed template CSV file\n",
    "template = pd.read_csv('DATA C-DESA NOBOREJO preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Konversi PDF ke PNG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new empty dataframe with the same columns as the template\n",
    "df = pd.DataFrame(columns=template.columns)\n",
    "df.head()\n",
    "\n",
    "# Make sure the PDF file is in the same directory as this script\n",
    "output_folder = 'Berkas Files/images of berkas 500-520 EXAMPLE 2/Preprocessed halaman 1 stuff'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Save CSV to the output directory\n",
    "output_dir = 'Berkas Files/images of berkas 500-520 EXAMPLE 2/Preprocessed halaman 1 stuff'\n",
    "output_file = 'output.csv'\n",
    "df.to_csv(os.path.join(output_dir, output_file), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved at:\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_1.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_2.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_3.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_4.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_5.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_6.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_7.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_8.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_9.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_10.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_11.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_12.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_13.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_14.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_15.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_16.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_17.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_18.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_19.png\n",
      "Berkas Files/images of berkas 500-520 EXAMPLE 2\\halaman_20.png\n"
     ]
    }
   ],
   "source": [
    "# Create subdirectory to hold images inside the Berkas Files subdirectory\n",
    "output_folder = 'Berkas Files/images of berkas 500-520 EXAMPLE 2'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Convert PDF to images\n",
    "pdf_path = 'Berkas Files/berkas 500-520 EXAMPLE 2.pdf'\n",
    "images = convert_from_path(pdf_path)\n",
    "\n",
    "# Save each image to the output folder\n",
    "for i, image in enumerate(images):\n",
    "    image_path = os.path.join(output_folder, f'halaman_{i+1}.png')\n",
    "    image.save(image_path, 'PNG')\n",
    "\n",
    "# Display the paths of the saved images\n",
    "image_paths = [os.path.join(output_folder, f'halaman_{i+1}.png') for i in range(len(images))]\n",
    "print(\"Images saved at:\")\n",
    "for path in image_paths:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image_path = 'Berkas Files/images of berkas 500-520 EXAMPLE 2/halaman_1.png'\n",
    "image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "if image is None:\n",
    "    raise ValueError(f\"Image not loaded. Check if the path is correct: {image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### !!! TESTING \"berkas 500-520 EXAMPLE 2.pdf !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image preprocessing attempt 1, **failed**\n",
    "\n",
    "Tried using: \n",
    "\n",
    "- **Tesseract OCR**: Used for extracting text from images.\n",
    "- **Image Preprocessing**:\n",
    "  - **Thresholding**: Applied adaptive thresholding to convert the image to a binary format.\n",
    "  - **Noise Removal**: Used morphological operations to remove noise from the image.\n",
    "  - **Contour Detection**: Detected contours to identify table structures in the image.\n",
    "- **Table Line Detection**: Highlighted table lines to improve OCR accuracy.\n",
    "\n",
    "Despite these efforts, we encountered challenges due to the poor quality of the scanned images and the handwritten text, which resulted in limited meaningful progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale (just in case)\\nadaptive_binary = cv2.adaptiveThreshold(\\n    gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 1001, 20  # Increased block size and constant\\n)\\n\\n# Save the output for this step\\nstep_1_path = os.path.join(output_dir, \\'Step 1 - Thickened Adaptive Thresholded Image.png\\')\\ncv2.imwrite(step_1_path, adaptive_binary)\\n\\nprint(f\"Step 1 completed. Thickened adaptive thresholded image saved at: {step_1_path}\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Apply refined adaptive thresholding with thicker lines\n",
    "'''\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale (just in case)\n",
    "adaptive_binary = cv2.adaptiveThreshold(\n",
    "    gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 1001, 20  # Increased block size and constant\n",
    ")\n",
    "\n",
    "# Save the output for this step\n",
    "step_1_path = os.path.join(output_dir, 'Step 1 - Thickened Adaptive Thresholded Image.png')\n",
    "cv2.imwrite(step_1_path, adaptive_binary)\n",
    "\n",
    "print(f\"Step 1 completed. Thickened adaptive thresholded image saved at: {step_1_path}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Adjust the bounding box to cover the hand\\nhand_region = (0, adaptive_binary.shape[0] - 800, 600, 1000)  # x, y, width, height\\nx, y, w, h = hand_region\\n\\n# Mask the hand by painting the region white\\nhand_removed = adaptive_binary.copy()\\ncv2.rectangle(hand_removed, (x, y), (x + w, y + h), (255, 255, 255), -1)\\n\\n# Save the cleaned image\\nstep_2_path = os.path.join(output_dir, \\'Step 2 - Hand Removed.png\\')\\ncv2.imwrite(step_2_path, hand_removed)\\n\\nprint(f\"Step 2 completed. Hand removed image saved at: {step_2_path}\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Remove unwanted hand region\n",
    "'''\n",
    "# Adjust the bounding box to cover the hand\n",
    "hand_region = (0, adaptive_binary.shape[0] - 800, 600, 1000)  # x, y, width, height\n",
    "x, y, w, h = hand_region\n",
    "\n",
    "# Mask the hand by painting the region white\n",
    "hand_removed = adaptive_binary.copy()\n",
    "cv2.rectangle(hand_removed, (x, y), (x + w, y + h), (255, 255, 255), -1)\n",
    "\n",
    "# Save the cleaned image\n",
    "step_2_path = os.path.join(output_dir, 'Step 2 - Hand Removed.png')\n",
    "cv2.imwrite(step_2_path, hand_removed)\n",
    "\n",
    "print(f\"Step 2 completed. Hand removed image saved at: {step_2_path}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntry:\\n    # Detect edges using Canny\\n    edges = cv2.Canny(hand_removed, 500, 1500)  # Adjust thresholds as needed (low_threshold, high_threshold)\\n\\n    # Dilate the edges to strengthen lines\\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))  # Adjust kernel size for line thickness\\n    dilated_edges = cv2.dilate(edges, kernel, iterations=1)\\n\\n    # Filter detected edges based on geometry (long horizontal/vertical lines)\\n    contours, _ = cv2.findContours(dilated_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\\n    mask = np.zeros_like(edges)  # Create a blank mask\\n    for contour in contours:\\n        x, y, w, h = cv2.boundingRect(contour)\\n        aspect_ratio = max(w, h) / min(w, h) if min(w, h) > 0 else 0\\n        # Keep only long horizontal or vertical lines\\n        if (w > 50 and h < 10) or (h > 50 and w < 10):  # Adjust thresholds as needed\\n            cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)\\n\\n    # Combine mask with dilated edges\\n    filtered_lines = cv2.bitwise_and(dilated_edges, mask)\\n\\n    # Convert grayscale image to BGR for color overlay\\n    table_lines_colored = cv2.merge([hand_removed, hand_removed, hand_removed])  # Grayscale to BGR\\n\\n    # Overlay green color on detected table lines\\n    table_lines_colored[filtered_lines > 0] = [0, 255, 0]  # Green (0, 255, 0)\\n\\n    # Save the resulting image\\n    step_3_path = os.path.join(output_dir, \\'Step 3 - Filtered Green Table Lines.png\\')\\n    cv2.imwrite(step_3_path, table_lines_colored)\\n\\n    print(f\"Step 3 completed. Filtered green table lines image saved at: {step_3_path}\")\\n\\nexcept Exception as e:\\n    print(f\"An error occurred in Step 3: {e}\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Highlight table lines in green (retain original background)\n",
    "'''\n",
    "try:\n",
    "    # Detect edges using Canny\n",
    "    edges = cv2.Canny(hand_removed, 500, 1500)  # Adjust thresholds as needed (low_threshold, high_threshold)\n",
    "\n",
    "    # Dilate the edges to strengthen lines\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))  # Adjust kernel size for line thickness\n",
    "    dilated_edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "    # Filter detected edges based on geometry (long horizontal/vertical lines)\n",
    "    contours, _ = cv2.findContours(dilated_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask = np.zeros_like(edges)  # Create a blank mask\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        aspect_ratio = max(w, h) / min(w, h) if min(w, h) > 0 else 0\n",
    "        # Keep only long horizontal or vertical lines\n",
    "        if (w > 50 and h < 10) or (h > 50 and w < 10):  # Adjust thresholds as needed\n",
    "            cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "    # Combine mask with dilated edges\n",
    "    filtered_lines = cv2.bitwise_and(dilated_edges, mask)\n",
    "\n",
    "    # Convert grayscale image to BGR for color overlay\n",
    "    table_lines_colored = cv2.merge([hand_removed, hand_removed, hand_removed])  # Grayscale to BGR\n",
    "\n",
    "    # Overlay green color on detected table lines\n",
    "    table_lines_colored[filtered_lines > 0] = [0, 255, 0]  # Green (0, 255, 0)\n",
    "\n",
    "    # Save the resulting image\n",
    "    step_3_path = os.path.join(output_dir, 'Step 3 - Filtered Green Table Lines.png')\n",
    "    cv2.imwrite(step_3_path, table_lines_colored)\n",
    "\n",
    "    print(f\"Step 3 completed. Filtered green table lines image saved at: {step_3_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred in Step 3: {e}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image preprocessing attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input path and output folder\n",
    "image_path = 'Berkas Files/images of berkas 500-520 EXAMPLE 2/halaman_1.png'\n",
    "output_folder = 'Berkas Files/images of berkas 500-520 EXAMPLE 2/Preprocessed halaman 1 stuff'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grayscale image saved at: Berkas Files/images of berkas 500-520 EXAMPLE 2/Preprocessed halaman 1 stuff\\halaman_1_gray.png\n"
     ]
    }
   ],
   "source": [
    "# Step 1.1. Convert to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Save the grayscale image\n",
    "output_path = os.path.join(output_folder, 'halaman_1_gray.png')\n",
    "cv2.imwrite(output_path, gray_image)\n",
    "\n",
    "print(f\"Grayscale image saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced contrast image saved at: Berkas Files/images of berkas 500-520 EXAMPLE 2/Preprocessed halaman 1 stuff\\halaman_1_contrast.png\n"
     ]
    }
   ],
   "source": [
    "# Step 1.2. Enhance contrast using CLAHE\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "enhanced_image = clahe.apply(gray_image)\n",
    "\n",
    "# Save the enhanced contrast image\n",
    "output_path = os.path.join(output_folder, 'halaman_1_contrast.png')\n",
    "cv2.imwrite(output_path, enhanced_image)\n",
    "\n",
    "print(f\"Enhanced contrast image saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoised image saved at: Berkas Files/images of berkas 500-520 EXAMPLE 2/Preprocessed halaman 1 stuff\\halaman_1_denoised.png\n"
     ]
    }
   ],
   "source": [
    "# Step 1.3. Remove noise using median blurring\n",
    "denoised_image = cv2.medianBlur(enhanced_image, 5)\n",
    "\n",
    "# Save the denoised image\n",
    "output_path = os.path.join(output_folder, 'halaman_1_denoised.png')\n",
    "cv2.imwrite(output_path, denoised_image)\n",
    "\n",
    "print(f\"Denoised image saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized image saved at: Berkas Files/images of berkas 500-520 EXAMPLE 2/Preprocessed halaman 1 stuff\\halaman_1_normalized.png\n"
     ]
    }
   ],
   "source": [
    "# Step 1.4. Normalize dimensions\n",
    "# Define the target dimensions\n",
    "target_width, target_height = 1024, 1024\n",
    "\n",
    "# Resize the image while preserving the aspect ratio\n",
    "h, w = denoised_image.shape\n",
    "scaling_factor = min(target_width / w, target_height / h)\n",
    "new_width = int(w * scaling_factor)\n",
    "new_height = int(h * scaling_factor)\n",
    "\n",
    "# Resize the image\n",
    "resized_image = cv2.resize(denoised_image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Pad the image to fit the target dimensions\n",
    "delta_w = target_width - new_width\n",
    "delta_h = target_height - new_height\n",
    "top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "normalized_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=255)\n",
    "\n",
    "# Save the normalized image\n",
    "output_path = os.path.join(output_folder, 'halaman_1_normalized.png')\n",
    "cv2.imwrite(output_path, normalized_image)\n",
    "\n",
    "print(f\"Normalized image saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Table Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Text Region Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Text Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Post-Processing and Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Memproses teks yang diekstrak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save ke dalam file Excel (file format '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
