{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ekstraksi dan Pengolahan Data Kepemilikan Tanah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Menyiapkan coding environment, termasuk menginstall dan/atau memperbarui library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pytesseract in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytesseract) (10.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pdf2image in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdf2image) (10.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pillow in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (10.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\emirp\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\emirp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Menginstall library-library\n",
    "%pip install pandas\n",
    "%pip install pytesseract\n",
    "%pip install pdf2image\n",
    "%pip install pillow\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install tensorflow\n",
    "%pip install opencv-python\n",
    "\n",
    "\n",
    "# Mengimport library-library untuk digunakan\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the preprocessed template CSV file\n",
    "template = pd.read_csv('DATA C-DESA NOBOREJO preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Konversi PDF ke PNG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new empty dataframe with the same columns as the template\n",
    "df = pd.DataFrame(columns=template.columns)\n",
    "df.head()\n",
    "\n",
    "# Make sure the PDF file is in the same directory as this script\n",
    "output_folder = 'Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Save CSV to the output directory\n",
    "output_dir = 'Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff'\n",
    "output_file = 'output.csv'\n",
    "df.to_csv(os.path.join(output_dir, output_file), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved at:\n",
      "Berkas Files/images of berkas 500-600\\halaman_1.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_2.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_3.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_4.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_5.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_6.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_7.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_8.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_9.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_10.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_11.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_12.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_13.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_14.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_15.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_16.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_17.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_18.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_19.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_20.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_21.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_22.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_23.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_24.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_25.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_26.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_27.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_28.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_29.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_30.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_31.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_32.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_33.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_34.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_35.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_36.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_37.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_38.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_39.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_40.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_41.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_42.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_43.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_44.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_45.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_46.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_47.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_48.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_49.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_50.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_51.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_52.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_53.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_54.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_55.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_56.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_57.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_58.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_59.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_60.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_61.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_62.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_63.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_64.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_65.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_66.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_67.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_68.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_69.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_70.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_71.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_72.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_73.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_74.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_75.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_76.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_77.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_78.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_79.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_80.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_81.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_82.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_83.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_84.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_85.png\n",
      "Berkas Files/images of berkas 500-600\\halaman_86.png\n"
     ]
    }
   ],
   "source": [
    "# Create subdirectory to hold images inside the Berkas Files subdirectory\n",
    "output_folder = 'Berkas Files/images of berkas 500-600'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Convert PDF to images\n",
    "pdf_path = 'Berkas Files/berkas 500-600.pdf'\n",
    "images = convert_from_path(pdf_path)\n",
    "\n",
    "# Save each image to the output folder\n",
    "for i, image in enumerate(images):\n",
    "    image_path = os.path.join(output_folder, f'halaman_{i+1}.png')\n",
    "    image.save(image_path, 'PNG')\n",
    "\n",
    "# Display the paths of the saved images\n",
    "image_paths = [os.path.join(output_folder, f'halaman_{i+1}.png') for i in range(len(images))]\n",
    "print(\"Images saved at:\")\n",
    "for path in image_paths:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image_path = 'Berkas Files/images of berkas 500-600/halaman_1.png'\n",
    "image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "if image is None:\n",
    "    raise ValueError(f\"Image not loaded. Check if the path is correct: {image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### !!! TESTING \"berkas 500-520 EXAMPLE 2.pdf !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image preprocessing attempt 1, **failed**\n",
    "\n",
    "Tried using: \n",
    "\n",
    "- **Tesseract OCR**: Used for extracting text from images.\n",
    "- **Image Preprocessing**:\n",
    "  - **Thresholding**: Applied adaptive thresholding to convert the image to a binary format.\n",
    "  - **Noise Removal**: Used morphological operations to remove noise from the image.\n",
    "  - **Contour Detection**: Detected contours to identify table structures in the image.\n",
    "- **Table Line Detection**: Highlighted table lines to improve OCR accuracy.\n",
    "\n",
    "Despite these efforts, we encountered challenges due to the poor quality of the scanned images and the handwritten text, which resulted in limited meaningful progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale (just in case)\\nadaptive_binary = cv2.adaptiveThreshold(\\n    gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 1001, 20  # Increased block size and constant\\n)\\n\\n# Save the output for this step\\nstep_1_path = os.path.join(output_dir, \\'Step 1 - Thickened Adaptive Thresholded Image.png\\')\\ncv2.imwrite(step_1_path, adaptive_binary)\\n\\nprint(f\"Step 1 completed. Thickened adaptive thresholded image saved at: {step_1_path}\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Apply refined adaptive thresholding with thicker lines\n",
    "'''\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale (just in case)\n",
    "adaptive_binary = cv2.adaptiveThreshold(\n",
    "    gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 1001, 20  # Increased block size and constant\n",
    ")\n",
    "\n",
    "# Save the output for this step\n",
    "step_1_path = os.path.join(output_dir, 'Step 1 - Thickened Adaptive Thresholded Image.png')\n",
    "cv2.imwrite(step_1_path, adaptive_binary)\n",
    "\n",
    "print(f\"Step 1 completed. Thickened adaptive thresholded image saved at: {step_1_path}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Adjust the bounding box to cover the hand\\nhand_region = (0, adaptive_binary.shape[0] - 800, 600, 1000)  # x, y, width, height\\nx, y, w, h = hand_region\\n\\n# Mask the hand by painting the region white\\nhand_removed = adaptive_binary.copy()\\ncv2.rectangle(hand_removed, (x, y), (x + w, y + h), (255, 255, 255), -1)\\n\\n# Save the cleaned image\\nstep_2_path = os.path.join(output_dir, \\'Step 2 - Hand Removed.png\\')\\ncv2.imwrite(step_2_path, hand_removed)\\n\\nprint(f\"Step 2 completed. Hand removed image saved at: {step_2_path}\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Remove unwanted hand region\n",
    "'''\n",
    "# Adjust the bounding box to cover the hand\n",
    "hand_region = (0, adaptive_binary.shape[0] - 800, 600, 1000)  # x, y, width, height\n",
    "x, y, w, h = hand_region\n",
    "\n",
    "# Mask the hand by painting the region white\n",
    "hand_removed = adaptive_binary.copy()\n",
    "cv2.rectangle(hand_removed, (x, y), (x + w, y + h), (255, 255, 255), -1)\n",
    "\n",
    "# Save the cleaned image\n",
    "step_2_path = os.path.join(output_dir, 'Step 2 - Hand Removed.png')\n",
    "cv2.imwrite(step_2_path, hand_removed)\n",
    "\n",
    "print(f\"Step 2 completed. Hand removed image saved at: {step_2_path}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntry:\\n    # Detect edges using Canny\\n    edges = cv2.Canny(hand_removed, 500, 1500)  # Adjust thresholds as needed (low_threshold, high_threshold)\\n\\n    # Dilate the edges to strengthen lines\\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))  # Adjust kernel size for line thickness\\n    dilated_edges = cv2.dilate(edges, kernel, iterations=1)\\n\\n    # Filter detected edges based on geometry (long horizontal/vertical lines)\\n    contours, _ = cv2.findContours(dilated_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\\n    mask = np.zeros_like(edges)  # Create a blank mask\\n    for contour in contours:\\n        x, y, w, h = cv2.boundingRect(contour)\\n        aspect_ratio = max(w, h) / min(w, h) if min(w, h) > 0 else 0\\n        # Keep only long horizontal or vertical lines\\n        if (w > 50 and h < 10) or (h > 50 and w < 10):  # Adjust thresholds as needed\\n            cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)\\n\\n    # Combine mask with dilated edges\\n    filtered_lines = cv2.bitwise_and(dilated_edges, mask)\\n\\n    # Convert grayscale image to BGR for color overlay\\n    table_lines_colored = cv2.merge([hand_removed, hand_removed, hand_removed])  # Grayscale to BGR\\n\\n    # Overlay green color on detected table lines\\n    table_lines_colored[filtered_lines > 0] = [0, 255, 0]  # Green (0, 255, 0)\\n\\n    # Save the resulting image\\n    step_3_path = os.path.join(output_dir, \\'Step 3 - Filtered Green Table Lines.png\\')\\n    cv2.imwrite(step_3_path, table_lines_colored)\\n\\n    print(f\"Step 3 completed. Filtered green table lines image saved at: {step_3_path}\")\\n\\nexcept Exception as e:\\n    print(f\"An error occurred in Step 3: {e}\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Highlight table lines in green (retain original background)\n",
    "'''\n",
    "try:\n",
    "    # Detect edges using Canny\n",
    "    edges = cv2.Canny(hand_removed, 500, 1500)  # Adjust thresholds as needed (low_threshold, high_threshold)\n",
    "\n",
    "    # Dilate the edges to strengthen lines\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))  # Adjust kernel size for line thickness\n",
    "    dilated_edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "    # Filter detected edges based on geometry (long horizontal/vertical lines)\n",
    "    contours, _ = cv2.findContours(dilated_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask = np.zeros_like(edges)  # Create a blank mask\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        aspect_ratio = max(w, h) / min(w, h) if min(w, h) > 0 else 0\n",
    "        # Keep only long horizontal or vertical lines\n",
    "        if (w > 50 and h < 10) or (h > 50 and w < 10):  # Adjust thresholds as needed\n",
    "            cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "    # Combine mask with dilated edges\n",
    "    filtered_lines = cv2.bitwise_and(dilated_edges, mask)\n",
    "\n",
    "    # Convert grayscale image to BGR for color overlay\n",
    "    table_lines_colored = cv2.merge([hand_removed, hand_removed, hand_removed])  # Grayscale to BGR\n",
    "\n",
    "    # Overlay green color on detected table lines\n",
    "    table_lines_colored[filtered_lines > 0] = [0, 255, 0]  # Green (0, 255, 0)\n",
    "\n",
    "    # Save the resulting image\n",
    "    step_3_path = os.path.join(output_dir, 'Step 3 - Filtered Green Table Lines.png')\n",
    "    cv2.imwrite(step_3_path, table_lines_colored)\n",
    "\n",
    "    print(f\"Step 3 completed. Filtered green table lines image saved at: {step_3_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred in Step 3: {e}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image preprocessing attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input path and output folder\n",
    "image_path = 'Berkas Files/images of berkas 500-600/halaman_1.png'\n",
    "output_folder = 'Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grayscale image saved at: Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff\\halaman_1_gray.png\n"
     ]
    }
   ],
   "source": [
    "# Step 1.1. Convert to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Save the grayscale image\n",
    "output_path = os.path.join(output_folder, 'halaman_1_gray.png')\n",
    "cv2.imwrite(output_path, gray_image)\n",
    "\n",
    "print(f\"Grayscale image saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced contrast image saved at: Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff\\halaman_1_contrast.png\n"
     ]
    }
   ],
   "source": [
    "# Step 1.2. Enhance contrast using CLAHE\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "enhanced_image = clahe.apply(gray_image)\n",
    "\n",
    "# Save the enhanced contrast image\n",
    "output_path = os.path.join(output_folder, 'halaman_1_contrast.png')\n",
    "cv2.imwrite(output_path, enhanced_image)\n",
    "\n",
    "print(f\"Enhanced contrast image saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoised image saved at: Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff\\halaman_1_denoised.png\n"
     ]
    }
   ],
   "source": [
    "# Step 1.3. Remove noise using median blurring\n",
    "denoised_image = cv2.medianBlur(enhanced_image, 5)\n",
    "\n",
    "# Save the denoised image\n",
    "output_path = os.path.join(output_folder, 'halaman_1_denoised.png')\n",
    "cv2.imwrite(output_path, denoised_image)\n",
    "\n",
    "print(f\"Denoised image saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized image saved at: Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff\\halaman_1_normalized.png\n"
     ]
    }
   ],
   "source": [
    "# Step 1.4. Normalize dimensions\n",
    "# Define the target dimensions\n",
    "target_width, target_height = 1024, 1024\n",
    "\n",
    "# Resize the image while preserving the aspect ratio\n",
    "h, w = denoised_image.shape\n",
    "scaling_factor = min(target_width / w, target_height / h)\n",
    "new_width = int(w * scaling_factor)\n",
    "new_height = int(h * scaling_factor)\n",
    "\n",
    "# Resize the image\n",
    "resized_image = cv2.resize(denoised_image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Pad the image to fit the target dimensions\n",
    "delta_w = target_width - new_width\n",
    "delta_h = target_height - new_height\n",
    "top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "normalized_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=255)\n",
    "\n",
    "# Save the normalized image\n",
    "output_path = os.path.join(output_folder, 'halaman_1_normalized.png')\n",
    "cv2.imwrite(output_path, normalized_image)\n",
    "\n",
    "print(f\"Normalized image saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Removing the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table structure image saved at: Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff/halaman_1_table_structure.png\n"
     ]
    }
   ],
   "source": [
    "# Step 2.1: Detect Table Structures\n",
    "\n",
    "# Threshold the image to binary\n",
    "_, binary = cv2.threshold(normalized_image, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Detect horizontal lines\n",
    "horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 1))\n",
    "horizontal_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "\n",
    "# Detect vertical lines\n",
    "vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 50))\n",
    "vertical_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel)\n",
    "\n",
    "# Combine horizontal and vertical lines\n",
    "table_structure = cv2.add(horizontal_lines, vertical_lines)\n",
    "\n",
    "# Optional: Dilate to merge gaps in table lines\n",
    "table_structure = cv2.dilate(table_structure, np.ones((3, 3), np.uint8))\n",
    "\n",
    "# Save the resulting table structure image\n",
    "output_path = 'Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff/halaman_1_table_structure.png'\n",
    "cv2.imwrite(output_path, table_structure)\n",
    "\n",
    "# Print confirmation and show the saved output\n",
    "print(f\"Table structure image saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text-only image saved at: Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff/halaman_1_text_only.png\n"
     ]
    }
   ],
   "source": [
    "# Step 2.2: Remove Table Structure to Extract Text\n",
    "\n",
    "# Normalize the table structure to binary (0 and 255)\n",
    "_, table_structure_binary = cv2.threshold(table_structure, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Create a mask where table lines are present\n",
    "table_lines_mask = table_structure_binary\n",
    "\n",
    "# Replace table lines in the normalized image with white\n",
    "text_only_image = cv2.add(normalized_image, table_lines_mask)\n",
    "\n",
    "# Save the resulting text-only image\n",
    "output_path = 'Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff/halaman_1_text_only.png'\n",
    "cv2.imwrite(output_path, text_only_image)\n",
    "\n",
    "# Print confirmation and save output\n",
    "print(f\"Text-only image saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Performing OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR result (sparse) saved at: Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff/halaman_1_ocr_output_sparse.txt\n",
      "OCR output (sparse):\n",
      "NAMA WAJIB IPEDA\n",
      "RING\n",
      "akan TANAH KE! _|\n",
      "Menara daftar “raindan\n",
      "Nomor eincan Sebab dan\n",
      "er Seer ‘anenl\n",
      "— Lees mith i Lane mie pee perobahan\n",
      "Shey ;\n",
      "Gos ae) at\n",
      "\n",
      "o_4es | a\n",
      "tive sie he\n",
      "“in 7\n",
      "\n",
      "4\n",
      "\n",
      "ilddataus\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3.1: Apply OCR to Extract Text\n",
    "# Specify OCR configurations\n",
    "custom_config = r'--psm 13 -c tessedit_char_whitelist=\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.,() \"'\n",
    "\n",
    "# Apply OCR on the text-only image\n",
    "ocr_result = pytesseract.image_to_string(text_only_image, lang='eng', config='custom_config')\n",
    "\n",
    "# Save OCR output to a text file\n",
    "output_path = 'Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff/halaman_1_ocr_output_sparse.txt'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(ocr_result)\n",
    "\n",
    "# Print confirmation and OCR result\n",
    "print(f\"OCR result (sparse) saved at: {output_path}\")\n",
    "print(\"OCR output (sparse):\")\n",
    "print(ocr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned OCR result saved at: Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff/halaman_1_ocr_cleaned.txt\n",
      "Cleaned OCR output:\n",
      "NAMA WAJIB IPEDA RING akan TANAH KE Menara daftar raindan Nomor eincan Sebab dan er Seer anenl Lees mith i Lane mie pee perobahan Shey Gos ae at o4es a tive sie he in 7 4 ilddataus\n"
     ]
    }
   ],
   "source": [
    "# Clean up the OCR result\n",
    "cleaned_ocr = re.sub(r'[^a-zA-Z0-9\\s.,]', '', ocr_result)  # Keep only alphanumeric and basic punctuation\n",
    "cleaned_ocr = re.sub(r'\\s+', ' ', cleaned_ocr).strip()  # Remove extra whitespace and trim\n",
    "\n",
    "# Save cleaned OCR output to a text file\n",
    "output_path_cleaned = 'Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff/halaman_1_ocr_cleaned.txt'\n",
    "with open(output_path_cleaned, 'w', encoding='utf-8') as f:\n",
    "    f.write(cleaned_ocr)\n",
    "\n",
    "# Print confirmation and cleaned output\n",
    "print(f\"Cleaned OCR result saved at: {output_path_cleaned}\")\n",
    "print(\"Cleaned OCR output:\")\n",
    "print(cleaned_ocr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final paginated OCR result saved to CSV at: Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff/halaman_1_ocr_paginated_final_header.csv\n",
      "CSV preview:\n",
      "  OCR Output                                                             ...  \\\n",
      "0   page_500  NAMA  WAJIB  IPEDA  RING  akan  TANAH  KE  Menara  daftar  ...   \n",
      "\n",
      "                                                    \n",
      "0  at  o4es  a  tive  sie  he  in  7  4  ilddataus  \n",
      "\n",
      "[1 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 3.3: Save OCR Output with Proper Header Placement\n",
    "\n",
    "# Define page identifier and header\n",
    "header = [\"OCR Output\"]\n",
    "page_id = \"page_500\"\n",
    "\n",
    "# Split cleaned OCR into individual words\n",
    "words = [page_id] + cleaned_ocr.split()\n",
    "\n",
    "# Create a DataFrame with words as a single row\n",
    "df = pd.DataFrame([words])\n",
    "\n",
    "# Update the header manually\n",
    "df.columns = header + [\"\" for _ in range(len(words) - 1)]\n",
    "\n",
    "# Save the DataFrame to a CSV\n",
    "csv_output_path = 'Berkas Files/images of berkas 500-600/Preprocessed halaman 1 stuff/halaman_1_ocr_paginated_final_header.csv'\n",
    "df.to_csv(csv_output_path, index=False, header=False)\n",
    "\n",
    "# Print confirmation and preview\n",
    "print(f\"Final paginated OCR result saved to CSV at: {csv_output_path}\")\n",
    "print(\"CSV preview:\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
